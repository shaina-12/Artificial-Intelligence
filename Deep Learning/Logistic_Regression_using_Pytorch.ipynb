{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression using Pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO3OqTxkE2n7F5b/n+GpQ7F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaina-12/Artificial-Intelligence/blob/main/Deep%20Learning/Logistic_Regression_using_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W1f-ajBDecFB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.MNIST('./data',download=True,train=True)\n",
        "test_data = datasets.MNIST('data',download=True,train=False)"
      ],
      "metadata": {
        "id": "QDTJr5XjlMxv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_data)"
      ],
      "metadata": {
        "id": "p2NqyguinPwe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35278c17-b4eb-4187-fdaf-9d21f0e840e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data)"
      ],
      "metadata": {
        "id": "p-VIVrwTlM1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b1c157f-60c8-4a06-a2d2-1b11ff4d2317"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7kbCFvcjZBk",
        "outputId": "cd2c531d-8c89-4425-9ae5-34807276f6f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<PIL.Image.Image image mode=L size=28x28 at 0x7F33FA189750>, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.subplot(1,2,1)\n",
        "image, label = training_data[0]\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title(\"Label of Image:{}\".format(label),fontsize=20)\n",
        "plt.subplot(1,2,2)\n",
        "image, label = training_data[1]\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title(\"Label of Image:{}\".format(label),fontsize=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "1eMrcwHmjcbO",
        "outputId": "c825139d-ed0d-4e72-bc80-3afcd5f9449a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Label of Image:0')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.MNIST('data',train=True,transform=ToTensor())\n",
        "test_data = datasets.MNIST('data',train=False,transform=ToTensor()) "
      ],
      "metadata": {
        "id": "DJjAaj9UjcgK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size= 100\n",
        "train_dl = DataLoader(training_data,batch_size=batch_size)\n",
        "test_dl = DataLoader(test_data,batch_size=batch_size)"
      ],
      "metadata": {
        "id": "EkY3moxIlM59"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X, y in test_dl:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKPoxpRnp1u4",
        "outputId": "133e8c59-6141-46b9-96ce-a872e1a86ac2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([100, 1, 28, 28])\n",
            "Shape of y: torch.Size([100]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 28*28  #Size of image\n",
        "num_classes = 10  #the image number are in range 0-10\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self,input_size,num_classes):\n",
        "    super(LogisticRegression,self).__init__()\n",
        "    self.linear = nn.Linear(input_size,num_classes)\n",
        "  def forward(self,x):\n",
        "    output = self.linear(x)\n",
        "    return output"
      ],
      "metadata": {
        "id": "78FFHIFxq_vc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(input_size,num_classes)\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimize = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "zN1u5Wveq_x8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = 0\n",
        "accuracy_score = 0\n",
        "for epoch in range(epochs):\n",
        "  for i, (images,labels) in enumerate(train_dl):\n",
        "    #labels = labels.unsqueeze(1)\n",
        "    images = torch.autograd.Variable(images.view(-1,input_size))\n",
        "    labels = torch.autograd.Variable(labels)\n",
        "    # nullify gradients w.r.t. parameters\n",
        "    optimize.zero_grad()\n",
        "    #forward propagation\n",
        "    output = model(images)\n",
        "    # compute loss based on obtained value and actual label\n",
        "    #print(output.shape)\n",
        "    #print(labels.shape)\n",
        "    compute_loss = loss_fn(output,labels)\n",
        "    # backward propagation\n",
        "    compute_loss.backward()\n",
        "    # update the parameters\n",
        "    optimize.step()\n",
        "    run+=1\n",
        "    if ((i+1)%200 == 0):\n",
        "      # check total accuracy of predicted value and actual label\n",
        "      accurate = 0\n",
        "      total = 0\n",
        "      for images,labels in test_dl:\n",
        "        images = torch.autograd.Variable(images.view(-1,input_size))\n",
        "        output = model(images)\n",
        "        _,predicted = torch.max(output.data, 1)\n",
        "        # total labels\n",
        "        total+= labels.size(0)\n",
        "        # Total correct predictions\n",
        "        accurate+= (predicted == labels).sum()\n",
        "        accuracy_score = 100 * accurate/total\n",
        "        print('Iteration: {}. Loss: {}. Accuracy: {}'.format(run, compute_loss.item(), accuracy_score))\n",
        "print('Final Accuracy:',accuracy_score)"
      ],
      "metadata": {
        "id": "dJP7Vb-rGVgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed2caf6-ce95-4568-e0e0-797eedbe0613"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.0\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.5\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 36.66666793823242\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 37.5\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 38.20000076293945\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 38.33333206176758\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 38.0\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.25\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.11111068725586\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.099998474121094\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 38.727272033691406\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 38.58333206176758\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 38.46154022216797\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 38.35714340209961\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 38.33333206176758\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 38.6875\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 38.52941131591797\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 38.61111068725586\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.105262756347656\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.45000076293945\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.095237731933594\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 38.818180084228516\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 38.65217208862305\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 38.875\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 38.720001220703125\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 38.730770111083984\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 38.592594146728516\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 38.89285659790039\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.2068977355957\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.06666564941406\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.16128921508789\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.0\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.09090805053711\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.235294342041016\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.25714111328125\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.44444274902344\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.56756591796875\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.47368240356445\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.33333206176758\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.275001525878906\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.585365295410156\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.42856979370117\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.348838806152344\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.20454406738281\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.20000076293945\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.28260803222656\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.29787063598633\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.27083206176758\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.306121826171875\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.36000061035156\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.490196228027344\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.53845977783203\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.622642517089844\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 39.87036895751953\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.01818084716797\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.05356979370117\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.07017517089844\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.08620834350586\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.220340728759766\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.25\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.16393280029297\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.225807189941406\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.4603157043457\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.5\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.523075103759766\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.56060791015625\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.35820770263672\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.514705657958984\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.449275970458984\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.58571243286133\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.64788818359375\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.625\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.671234130859375\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.702701568603516\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.7066650390625\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.8684196472168\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 40.844154357910156\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 41.089744567871094\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 41.177215576171875\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 41.275001525878906\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 41.48147964477539\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 41.4878044128418\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 41.51807403564453\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 41.57143020629883\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 41.599998474121094\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 41.72093200683594\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 41.8505744934082\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 41.977272033691406\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 42.15730285644531\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 42.266666412353516\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 42.263736724853516\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 42.28260803222656\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 42.33333206176758\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 42.446807861328125\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 42.547367095947266\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 42.53125\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 42.56700897216797\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 42.591835021972656\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 42.69696807861328\n",
            "Iteration: 200. Loss: 2.0933189392089844. Accuracy: 42.81999969482422\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.0\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.0\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 54.33333206176758\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 55.25\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 56.400001525878906\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 56.83333206176758\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 55.85714340209961\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 56.5\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.22222137451172\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.099998474121094\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.0\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.25\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 56.53845977783203\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 56.71428680419922\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 56.66666793823242\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.0\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.05882263183594\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.27777862548828\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.52631759643555\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.5\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.28571319580078\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.181819915771484\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.043479919433594\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.33333206176758\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.20000076293945\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 56.96154022216797\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 56.703704833984375\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.10714340209961\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.41379165649414\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.33333206176758\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.6129035949707\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.375\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.6363639831543\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.735294342041016\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.85714340209961\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.83333206176758\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 58.054054260253906\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.97368240356445\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.846153259277344\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.79999923706055\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.92683029174805\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.83333206176758\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.627906799316406\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.6363639831543\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.53333282470703\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.60869598388672\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.65957260131836\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.72916793823242\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.775508880615234\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.7599983215332\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 57.94117736816406\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 58.05769348144531\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 58.24528121948242\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 58.61111068725586\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 58.92727279663086\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 59.0\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 59.03508758544922\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 59.27586364746094\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 59.305084228515625\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 59.266666412353516\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 59.11475372314453\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 59.24193572998047\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 59.55555725097656\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 59.703125\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 59.86153793334961\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 59.878787994384766\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 59.835819244384766\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 59.92647171020508\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 59.89855194091797\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 60.099998474121094\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 60.239437103271484\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 60.34722137451172\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 60.45205307006836\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 60.58108139038086\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 60.54666519165039\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 60.6315803527832\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 60.68831253051758\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 60.88461685180664\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 60.89873504638672\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 61.0\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 61.11111068725586\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 61.14634323120117\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 61.192771911621094\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 61.21428680419922\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 61.17647171020508\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 61.27906799316406\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 61.43678283691406\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 61.70454406738281\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 61.88764190673828\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 62.0444450378418\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 62.021976470947266\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 62.03260803222656\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 62.04301071166992\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 62.1489372253418\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 62.17894744873047\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 62.28125\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 62.32989501953125\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 62.25510025024414\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 62.272727966308594\n",
            "Iteration: 400. Loss: 1.9569694995880127. Accuracy: 62.34000015258789\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 67.0\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.0\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 64.33333587646484\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 64.25\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 64.4000015258789\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 65.16666412353516\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 64.14286041259766\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 65.0\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 65.55555725097656\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 65.30000305175781\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 65.2727279663086\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 65.33333587646484\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 64.53845977783203\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 64.85713958740234\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 64.66666412353516\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 65.25\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 65.47058868408203\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 65.61111450195312\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 65.9473648071289\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.1500015258789\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 65.85713958740234\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 65.68181610107422\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 65.78260803222656\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.04166412353516\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.12000274658203\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.07691955566406\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.0\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.32142639160156\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.5862045288086\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.56666564941406\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.83870697021484\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.625\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.7272720336914\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.73529052734375\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.82857513427734\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.72222137451172\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.9189224243164\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.7631607055664\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.4871826171875\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.4749984741211\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.53658294677734\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.52381134033203\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.34883880615234\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.34091186523438\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.24444580078125\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.3043441772461\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.38298034667969\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.52083587646484\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.46939086914062\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.4800033569336\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.64705657958984\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 66.84615325927734\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 67.01886749267578\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 67.33333587646484\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 67.69091033935547\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 67.75\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 67.84210205078125\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 68.10344696044922\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 68.18643951416016\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 68.13333129882812\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 68.0655746459961\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 68.17742156982422\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 68.47618865966797\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 68.65625\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 68.80000305175781\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 68.8484878540039\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 68.82089233398438\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 68.8382339477539\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 68.79710388183594\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 69.0\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 69.1408462524414\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 69.22222137451172\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 69.27397155761719\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 69.5\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 69.38666534423828\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 69.38157653808594\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 69.44155883789062\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 69.62820434570312\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 69.64556884765625\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 69.75\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 69.85185241699219\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 69.8780517578125\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 69.89156341552734\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 69.96428680419922\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 69.92941284179688\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 70.0\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 70.17241668701172\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 70.40908813476562\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 70.60674285888672\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 70.74444580078125\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 70.70330047607422\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 70.73912811279297\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 70.73118591308594\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 70.84042358398438\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 70.93684387207031\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 71.05208587646484\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 71.08247375488281\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 71.01020050048828\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 71.02020263671875\n",
            "Iteration: 600. Loss: 1.8426955938339233. Accuracy: 71.05000305175781\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.0\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.5\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.33333587646484\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.25\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.4000015258789\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.5\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.57142639160156\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.5\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 70.22222137451172\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.80000305175781\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.54545593261719\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.66666412353516\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.76923370361328\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.85713958740234\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.46666717529297\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.75\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.76470947265625\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.72222137451172\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.0\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.19999694824219\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.9047622680664\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.45454406738281\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.43478393554688\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.75\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.72000122070312\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.65384674072266\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.59259033203125\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.92857360839844\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.10344696044922\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.0\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.2258071899414\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.0\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.24242401123047\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.23529052734375\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.34285736083984\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.19444274902344\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.35134887695312\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.15789794921875\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.97435760498047\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.05000305175781\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.04878234863281\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.04762268066406\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.88372039794922\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.79545593261719\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.77777862548828\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.8043441772461\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.89361572265625\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.02083587646484\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.91836547851562\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 68.9000015258789\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.07843017578125\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.25\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.4339599609375\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 69.70370483398438\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 70.03636169433594\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 70.05357360839844\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 70.1754379272461\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 70.39655303955078\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 70.49152374267578\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 70.46666717529297\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 70.45901489257812\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 70.61289978027344\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 70.9206314086914\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 71.078125\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 71.30769348144531\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 71.36363983154297\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 71.35820770263672\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 71.3382339477539\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 71.34782409667969\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 71.52857208251953\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 71.63380432128906\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 71.69444274902344\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 71.79451751708984\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 72.01351165771484\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 71.90666961669922\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 71.9473648071289\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 71.97402954101562\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 72.12820434570312\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 72.15190124511719\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 72.25\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 72.30863952636719\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 72.3780517578125\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 72.4337387084961\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 72.51190185546875\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 72.4941177368164\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 72.5813980102539\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 72.73563385009766\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 72.9772720336914\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 73.17977905273438\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 73.36666870117188\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 73.30769348144531\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 73.34782409667969\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 73.36559295654297\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 73.44680786132812\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 73.54737091064453\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 73.64583587646484\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 73.70103454589844\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 73.63265228271484\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 73.60606384277344\n",
            "Iteration: 800. Loss: 1.698433518409729. Accuracy: 73.61000061035156\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.0\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.5\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 72.33333587646484\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 72.0\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 72.4000015258789\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 72.16666412353516\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.28571319580078\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.875\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 72.44444274902344\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.9000015258789\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.63636016845703\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.83333587646484\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 70.92308044433594\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.07142639160156\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 70.93333435058594\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.125\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.17646789550781\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.11111450195312\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.31578826904297\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.5\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.23809814453125\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 70.95454406738281\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.0\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.29166412353516\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.4000015258789\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.26923370361328\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.29629516601562\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.75\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.93103790283203\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.86666870117188\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 72.19355010986328\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.9375\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 72.1212158203125\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 72.14705657958984\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 72.28571319580078\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 72.11111450195312\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 72.27027130126953\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 72.07894897460938\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.92308044433594\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.9749984741211\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.95121765136719\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.97618865966797\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.79069519042969\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.68181610107422\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.62222290039062\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.65217590332031\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.7021255493164\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.85416412353516\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.69387817382812\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.66000366210938\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 71.82353210449219\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 72.07691955566406\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 72.28302001953125\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 72.51851654052734\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 72.83636474609375\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 72.875\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 72.96491241455078\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 73.10344696044922\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 73.15254211425781\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 73.11666870117188\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 73.19672393798828\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 73.37096405029297\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 73.68254089355469\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 73.859375\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 74.07691955566406\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 74.09091186523438\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 74.13433074951172\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 74.11764526367188\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 74.18840789794922\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 74.35713958740234\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 74.4507064819336\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 74.54166412353516\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 74.61643981933594\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 74.79729461669922\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 74.6933364868164\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 74.71052551269531\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 74.71428680419922\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 74.88461303710938\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 74.89873504638672\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 75.01249694824219\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 75.06172943115234\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 75.10975646972656\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 75.1927719116211\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 75.26190185546875\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 75.24705505371094\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 75.34883880615234\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 75.50574493408203\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 75.75\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 75.93258666992188\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 76.12222290039062\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 76.0879135131836\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 76.15217590332031\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 76.1505355834961\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 76.27659606933594\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 76.36842346191406\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 76.44791412353516\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 76.47422790527344\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 76.38775634765625\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 76.3535385131836\n",
            "Iteration: 1000. Loss: 1.6114236116409302. Accuracy: 76.3499984741211\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 72.0\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.0\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.66666412353516\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.0\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.0\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.16666412353516\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.42857360839844\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.25\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.55555725097656\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.19999694824219\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.0\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.16666412353516\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.53845977783203\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.64286041259766\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.19999694824219\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.5\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.47058868408203\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.5\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.63157653808594\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.69999694824219\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.47618865966797\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.2272720336914\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.34782409667969\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.54166412353516\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.5999984741211\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.53845977783203\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.55555725097656\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.92857360839844\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.10344696044922\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.03333282470703\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.3548355102539\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.0625\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.24242401123047\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.23529052734375\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.37142944335938\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.19444274902344\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.29729461669922\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.0526351928711\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.92308044433594\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.94999694824219\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.95121765136719\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.97618865966797\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.79069519042969\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.65908813476562\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.55555725097656\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.63043212890625\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.68085479736328\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.79166412353516\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.61224365234375\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.5199966430664\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.68627166748047\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 73.90384674072266\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.07546997070312\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.37036895751953\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.70909118652344\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.75\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.84210205078125\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 75.0\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 75.03389739990234\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 74.98332977294922\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 75.09835815429688\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 75.24193572998047\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 75.61904907226562\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 75.796875\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 76.0\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 76.03030395507812\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 76.05970001220703\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 76.07353210449219\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 76.159423828125\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 76.30000305175781\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 76.38027954101562\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 76.47222137451172\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 76.5753402709961\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 76.74324035644531\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 76.65333557128906\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 76.63157653808594\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 76.64935302734375\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 76.79486846923828\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 76.7848129272461\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 76.9000015258789\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 76.91358184814453\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 76.95121765136719\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 77.02409362792969\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 77.0952377319336\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 77.10588073730469\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 77.18604278564453\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 77.3448257446289\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 77.57954406738281\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 77.76404571533203\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 77.9111099243164\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 77.85713958740234\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 77.92391204833984\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 77.91397857666016\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 78.05319213867188\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 78.1894760131836\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 78.26041412353516\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 78.2680435180664\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 78.16326904296875\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 78.1212158203125\n",
            "Iteration: 1200. Loss: 1.5605781078338623. Accuracy: 78.12000274658203\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 72.0\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.5\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 75.33333587646484\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.75\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.5999984741211\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.83333587646484\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.28571319580078\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 75.0\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 75.44444274902344\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 75.0\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.7272720336914\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.83333587646484\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.15384674072266\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.14286041259766\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 73.86666870117188\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.125\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.11764526367188\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.11111450195312\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.2631607055664\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.3499984741211\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.0952377319336\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 73.81818389892578\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 73.9565200805664\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.16666412353516\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.23999786376953\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.07691955566406\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.11111450195312\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.5\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.6551742553711\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.56666564941406\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.93548583984375\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.71875\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.8787841796875\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.82353210449219\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 75.02857208251953\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.80555725097656\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.9189224243164\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.71052551269531\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.5897445678711\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.5999984741211\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.58536529541016\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.5952377319336\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.44186401367188\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.2727279663086\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.17778015136719\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.28260803222656\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.38298034667969\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.45833587646484\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.26530456542969\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.22000122070312\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.37255096435547\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.59615325927734\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 74.75471496582031\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 75.05555725097656\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 75.41818237304688\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 75.46428680419922\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 75.52631378173828\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 75.67241668701172\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 75.69491577148438\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 75.63333129882812\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 75.75409698486328\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 75.91935729980469\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 76.25396728515625\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 76.421875\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 76.63076782226562\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 76.6515121459961\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 76.70149230957031\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 76.69117736816406\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 76.72463989257812\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 76.85713958740234\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 76.95774841308594\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 77.05555725097656\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 77.15068817138672\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 77.32432556152344\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 77.22666931152344\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 77.2368392944336\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 77.2597427368164\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 77.3974380493164\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 77.37974548339844\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 77.51249694824219\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 77.543212890625\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 77.59756469726562\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 77.65060424804688\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 77.72618865966797\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 77.74117279052734\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 77.8255844116211\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 77.96551513671875\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 78.18181610107422\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 78.35955047607422\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 78.54444122314453\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 78.53845977783203\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 78.58695983886719\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 78.59140014648438\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 78.69149017333984\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 78.82105255126953\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 78.89583587646484\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 78.9278335571289\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 78.84693908691406\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 78.78787994384766\n",
            "Iteration: 1400. Loss: 1.4405370950698853. Accuracy: 78.7699966430664\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.0\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 77.5\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 77.33333587646484\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 76.75\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 76.4000015258789\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 76.16666412353516\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.71428680419922\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 76.375\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 76.77777862548828\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 76.30000305175781\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 76.09091186523438\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 76.16666412353516\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.38461303710938\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.35713958740234\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.13333129882812\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.375\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.29412078857422\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.22222137451172\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.31578826904297\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.3499984741211\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.04762268066406\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 74.7727279663086\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 74.91304016113281\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.08333587646484\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.16000366210938\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.0\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.03704071044922\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.42857360839844\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.55172729492188\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.5\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.90322875976562\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.65625\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.8484878540039\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.76470947265625\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.97142791748047\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.80555725097656\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.9189224243164\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.7631607055664\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.64102935791016\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.6500015258789\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.63414764404297\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.61904907226562\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.48837280273438\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.31818389892578\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.22222137451172\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.3043441772461\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.44680786132812\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.54166412353516\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.34693908691406\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.27999877929688\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.4313735961914\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.67308044433594\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 75.86792755126953\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 76.14814758300781\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 76.50909423828125\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 76.57142639160156\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 76.63157653808594\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 76.77586364746094\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 76.7796630859375\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 76.69999694824219\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 76.80327606201172\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 76.96774291992188\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 77.31745910644531\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 77.484375\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 77.69230651855469\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 77.71212005615234\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 77.7313461303711\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 77.72058868408203\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 77.76811218261719\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 77.88571166992188\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 77.97183227539062\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 78.06944274902344\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 78.16438293457031\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 78.35134887695312\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 78.23999786376953\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 78.25\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 78.31169128417969\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 78.44871520996094\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 78.44303894042969\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 78.57499694824219\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 78.62963104248047\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 78.67073059082031\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 78.72289276123047\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 78.80952453613281\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 78.83529663085938\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 78.94186401367188\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 79.09195709228516\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 79.29545593261719\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 79.47190856933594\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 79.64444732666016\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 79.62637329101562\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 79.7065200805664\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 79.69892120361328\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 79.85106658935547\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 79.97895050048828\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 80.04166412353516\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 80.06185913085938\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 79.9795913696289\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 79.90908813476562\n",
            "Iteration: 1600. Loss: 1.3850311040878296. Accuracy: 79.88999938964844\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 75.0\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 77.5\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 77.66666412353516\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 77.5\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 77.19999694824219\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 77.0\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.57142639160156\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 77.125\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 77.33333587646484\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.9000015258789\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.81818389892578\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.83333587646484\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.0\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.0\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 75.80000305175781\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.0625\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.05882263183594\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 75.94444274902344\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.0\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.0\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 75.66666412353516\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 75.40908813476562\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 75.56521606445312\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 75.70833587646484\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 75.80000305175781\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 75.65384674072266\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 75.74073791503906\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.10713958740234\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.24137878417969\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.23332977294922\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.61289978027344\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.375\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.54545593261719\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.47058868408203\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.5999984741211\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.41666412353516\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.54054260253906\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.36842346191406\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.23076629638672\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.2249984741211\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.24390411376953\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.26190185546875\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.13953399658203\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 75.9772720336914\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 75.86666870117188\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 75.93478393554688\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.0851058959961\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.16666412353516\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 75.9795913696289\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 75.91999816894531\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.07843017578125\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.32691955566406\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.52830505371094\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 76.81481170654297\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 77.16363525390625\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 77.21428680419922\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 77.28070068359375\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 77.4137954711914\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 77.40677642822266\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 77.31666564941406\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 77.40983581542969\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 77.59677124023438\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 77.93650817871094\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 78.109375\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 78.32307434082031\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 78.33333587646484\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 78.3432846069336\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 78.32353210449219\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 78.36231994628906\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 78.47142791748047\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 78.591552734375\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 78.68055725097656\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 78.76712036132812\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 78.9459457397461\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 78.82666778564453\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 78.82894897460938\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 78.88311767578125\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 79.0128173828125\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 78.98734283447266\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 79.125\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 79.18518829345703\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 79.25609588623047\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 79.3132553100586\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 79.4047622680664\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 79.45882415771484\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 79.56977081298828\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 79.72413635253906\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 79.93181610107422\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 80.11235809326172\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 80.27777862548828\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 80.25274658203125\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 80.33695983886719\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 80.33333587646484\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 80.47872161865234\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 80.5999984741211\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 80.65625\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 80.64948272705078\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 80.56122589111328\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 80.48484802246094\n",
            "Iteration: 1800. Loss: 1.3654850721359253. Accuracy: 80.45999908447266\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 77.0\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 78.5\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 78.33333587646484\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 78.25\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 77.80000305175781\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 77.5\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 77.0\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 77.625\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 78.0\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 77.5\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 77.45454406738281\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 77.33333587646484\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.53845977783203\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.5\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.19999694824219\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.4375\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.47058868408203\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.38888549804688\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.42105102539062\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.4000015258789\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.0952377319336\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 75.7272720336914\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 75.91304016113281\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.04166412353516\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.08000183105469\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 75.88461303710938\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 75.96295928955078\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.32142639160156\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.44827270507812\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.46666717529297\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.83870697021484\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.625\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.75757598876953\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.67646789550781\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.82857513427734\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.61111450195312\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.75675964355469\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.57894897460938\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.46154022216797\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.4749984741211\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.53658294677734\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.54762268066406\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.46511840820312\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.29545593261719\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.17778015136719\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.28260803222656\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.40425872802734\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.47916412353516\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.32653045654297\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.27999877929688\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.4313735961914\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.67308044433594\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 76.84906005859375\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 77.11111450195312\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 77.49090576171875\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 77.51786041259766\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 77.57894897460938\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 77.72413635253906\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 77.71186065673828\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 77.63333129882812\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 77.7213134765625\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 77.90322875976562\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 78.23809814453125\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 78.390625\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 78.61538696289062\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 78.6212158203125\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 78.62686920166016\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 78.60294342041016\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 78.63768005371094\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 78.74285888671875\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 78.8591537475586\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 78.95833587646484\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 79.05479431152344\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 79.22972869873047\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 79.12000274658203\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 79.13157653808594\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 79.19480895996094\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 79.32051086425781\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 79.30379486083984\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 79.4375\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 79.49382781982422\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 79.58536529541016\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 79.65060424804688\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 79.75\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 79.82353210449219\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 79.9186019897461\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 80.06896209716797\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 80.2727279663086\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 80.4494400024414\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 80.61111450195312\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 80.5934066772461\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 80.67391204833984\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 80.66666412353516\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 80.7978744506836\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 80.91578674316406\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 80.97916412353516\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 80.97937774658203\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 80.88775634765625\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 80.8080825805664\n",
            "Iteration: 2000. Loss: 1.2659096717834473. Accuracy: 80.77999877929688\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.0\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 80.0\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 79.66666412353516\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 79.25\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 78.80000305175781\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 78.66666412353516\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 78.14286041259766\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 78.625\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 78.88888549804688\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 78.5\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 78.2727279663086\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 78.16666412353516\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.30769348144531\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.21428680419922\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 76.93333435058594\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.125\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.17646789550781\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.05555725097656\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.10526275634766\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.05000305175781\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 76.80952453613281\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 76.5\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 76.73912811279297\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 76.875\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 76.91999816894531\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 76.76923370361328\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 76.81481170654297\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.14286041259766\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.27586364746094\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.26667022705078\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.58064270019531\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.375\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.48484802246094\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.38235473632812\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.4857177734375\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.30555725097656\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.43243408203125\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.2631607055664\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.15384674072266\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.1500015258789\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.17073059082031\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.21428680419922\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.16278839111328\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.0\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 76.86666870117188\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 76.9565200805664\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.10638427734375\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.1875\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.0204086303711\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 76.9800033569336\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.13725280761719\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.36538696289062\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.60377502441406\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 77.88888549804688\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 78.23636627197266\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 78.28571319580078\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 78.33333587646484\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 78.46551513671875\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 78.44068145751953\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 78.38333129882812\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 78.45901489257812\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 78.62903594970703\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 78.95237731933594\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 79.109375\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 79.29230499267578\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 79.30303192138672\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 79.32836151123047\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 79.29412078857422\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 79.33333587646484\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 79.45714569091797\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 79.5633773803711\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 79.65277862548828\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 79.72602844238281\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 79.89189147949219\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 79.78666687011719\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 79.81578826904297\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 79.88311767578125\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 80.0128173828125\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 80.0\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 80.125\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 80.18518829345703\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 80.28048706054688\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 80.34939575195312\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 80.46428680419922\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 80.52941131591797\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 80.65116119384766\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 80.80459594726562\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 81.0\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 81.17977905273438\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 81.33333587646484\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 81.30769348144531\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 81.39130401611328\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 81.3978500366211\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 81.54255676269531\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 81.66315460205078\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 81.70833587646484\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 81.70103454589844\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 81.60204315185547\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 81.52525329589844\n",
            "Iteration: 2200. Loss: 1.2298656702041626. Accuracy: 81.51000213623047\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.0\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 79.5\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 79.33333587646484\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 79.0\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 78.5999984741211\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 78.5\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 78.0\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 78.625\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 78.77777862548828\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 78.4000015258789\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 78.2727279663086\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 78.16666412353516\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.30769348144531\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.28571319580078\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.0\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.25\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.29412078857422\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.33333587646484\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.31578826904297\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.25\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 76.95237731933594\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 76.63636016845703\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 76.86956787109375\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.0\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.04000091552734\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 76.92308044433594\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.0\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.32142639160156\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.44827270507812\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.46666717529297\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.83870697021484\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.625\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.7272720336914\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.64705657958984\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.77143096923828\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.63888549804688\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.75675964355469\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.57894897460938\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.4871826171875\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.4749984741211\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.53658294677734\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.5952377319336\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.51162719726562\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.34091186523438\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.22222137451172\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.28260803222656\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.42552947998047\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.5\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.32653045654297\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.26000213623047\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.4117660522461\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.63461303710938\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 77.86792755126953\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 78.18518829345703\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 78.52727508544922\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 78.57142639160156\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 78.63157653808594\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 78.75862121582031\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 78.74576568603516\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 78.68333435058594\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 78.75409698486328\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 78.95161437988281\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 79.28571319580078\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 79.46875\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 79.67692565917969\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 79.68181610107422\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 79.71641540527344\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 79.67646789550781\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 79.71014404296875\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 79.82857513427734\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 79.94366455078125\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 80.02777862548828\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 80.09589385986328\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 80.25675964355469\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 80.17333221435547\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 80.21052551269531\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 80.2727279663086\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 80.4102554321289\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 80.39240264892578\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 80.5250015258789\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 80.59259033203125\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 80.68292999267578\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 80.73493957519531\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 80.86904907226562\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 80.95294189453125\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 81.06977081298828\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 81.21839141845703\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 81.40908813476562\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 81.58426666259766\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 81.72222137451172\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 81.70330047607422\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 81.78260803222656\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 81.78494262695312\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 81.92552947998047\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 82.04210662841797\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 82.08333587646484\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 82.05154418945312\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 81.95918273925781\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 81.8787841796875\n",
            "Iteration: 2400. Loss: 1.2257732152938843. Accuracy: 81.8499984741211\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.0\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 80.5\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 80.0\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 79.75\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 79.19999694824219\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 79.0\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 78.42857360839844\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 79.0\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 79.44444274902344\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 78.9000015258789\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 78.7272720336914\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 78.66666412353516\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.76923370361328\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.85713958740234\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.53333282470703\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.75\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.76470947265625\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.72222137451172\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.68421173095703\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.5999984741211\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.33333587646484\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.09091186523438\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.3043441772461\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.41666412353516\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.44000244140625\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.23076629638672\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.25926208496094\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.57142639160156\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.72413635253906\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.73332977294922\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 78.09677124023438\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.90625\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 78.0\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.85294342041016\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.94285583496094\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.80555725097656\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.9189224243164\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.71052551269531\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.61538696289062\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.5999984741211\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.63414764404297\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.69047546386719\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.60465240478516\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.45454406738281\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.35555267333984\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.43478393554688\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.55319213867188\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.64583587646484\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.46939086914062\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.45999908447266\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.62744903564453\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 77.84615325927734\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 78.0943374633789\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 78.40740966796875\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 78.78181457519531\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 78.80357360839844\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 78.84210205078125\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 78.96551513671875\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 78.94915008544922\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 78.9000015258789\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 78.95082092285156\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 79.1451644897461\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 79.47618865966797\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 79.640625\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 79.84615325927734\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 79.86363983154297\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 79.89552307128906\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 79.85294342041016\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 79.8840560913086\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 80.0\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 80.09859466552734\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 80.20833587646484\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 80.3013687133789\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 80.45945739746094\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 80.37333679199219\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 80.39473724365234\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 80.45454406738281\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 80.5897445678711\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 80.56961822509766\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 80.69999694824219\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 80.76543426513672\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 80.8536605834961\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 80.91566467285156\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 81.04762268066406\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 81.12940979003906\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 81.24418640136719\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 81.39080810546875\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 81.57954406738281\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 81.7528076171875\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 81.9000015258789\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 81.85713958740234\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 81.93478393554688\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 81.93548583984375\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 82.07447052001953\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 82.1894760131836\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 82.22916412353516\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 82.21649169921875\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 82.12245178222656\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 82.03030395507812\n",
            "Iteration: 2600. Loss: 1.1419388055801392. Accuracy: 81.98999786376953\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 79.0\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 81.5\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 81.0\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 80.25\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 79.5999984741211\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 79.33333587646484\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.71428680419922\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 79.375\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 80.0\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 79.5999984741211\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 79.36363983154297\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 79.33333587646484\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.38461303710938\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.42857360839844\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.06666564941406\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.3125\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.4117660522461\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.33333587646484\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.36842346191406\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.25\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 77.95237731933594\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 77.68181610107422\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 77.86956787109375\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.0\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.0\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 77.92308044433594\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 77.96295928955078\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.25\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.37931060791016\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.4000015258789\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.70967864990234\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.53125\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.60606384277344\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.47058868408203\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.57142639160156\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.44444274902344\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.54054260253906\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.34210205078125\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.23076629638672\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.2249984741211\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.24390411376953\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.30952453613281\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.20930480957031\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.04545593261719\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 77.97777557373047\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.06521606445312\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.17021179199219\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.27083587646484\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.12245178222656\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.12000274658203\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.29412078857422\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.5\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 78.73584747314453\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 79.03704071044922\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 79.38182067871094\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 79.42857360839844\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 79.47368621826172\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 79.62068939208984\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 79.59322357177734\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 79.53333282470703\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 79.57376861572266\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 79.75806427001953\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 80.0793685913086\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 80.25\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 80.43077087402344\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 80.43939208984375\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 80.46268463134766\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 80.42646789550781\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 80.44927215576172\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 80.54285430908203\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 80.66197204589844\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 80.77777862548828\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 80.84931182861328\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 81.01351165771484\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 80.94666290283203\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 81.0\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 81.05194854736328\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 81.19230651855469\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 81.16455841064453\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 81.2750015258789\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 81.3456802368164\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 81.45121765136719\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 81.51807403564453\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 81.64286041259766\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 81.71764373779297\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 81.83721160888672\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 81.9885025024414\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 82.17045593261719\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 82.33708190917969\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 82.47777557373047\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 82.45054626464844\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 82.52173614501953\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 82.51612854003906\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 82.65957641601562\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 82.76841735839844\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 82.79166412353516\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 82.76288604736328\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 82.67346954345703\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 82.58586120605469\n",
            "Iteration: 2800. Loss: 1.1186672449111938. Accuracy: 82.54000091552734\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 79.0\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 82.0\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 81.66666412353516\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 80.75\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 80.0\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 79.5\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.71428680419922\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 79.375\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 79.88888549804688\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 79.5999984741211\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 79.45454406738281\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 79.5\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.46154022216797\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.5\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.13333129882812\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.375\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.47058868408203\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.44444274902344\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.47368621826172\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.4000015258789\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.19047546386719\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 77.90908813476562\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.08695983886719\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.20833587646484\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.19999694824219\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.15384674072266\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.22222137451172\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.5\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.6551742553711\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.66666412353516\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 79.0\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.8125\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.8787841796875\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.76470947265625\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.85713958740234\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.75\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.83783721923828\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.63157653808594\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.5128173828125\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.5\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.53658294677734\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.57142639160156\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.46511840820312\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.2727279663086\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.19999694824219\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.3043441772461\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.44680786132812\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.58333587646484\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.44898223876953\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.44000244140625\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.60784149169922\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 78.82691955566406\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 79.05660247802734\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 79.35185241699219\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 79.69091033935547\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 79.75\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 79.78947448730469\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 79.96551513671875\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 79.98304748535156\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 79.91666412353516\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 79.95082092285156\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 80.12903594970703\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 80.44444274902344\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 80.625\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 80.80000305175781\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 80.80303192138672\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 80.82089233398438\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 80.76470947265625\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 80.78260803222656\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 80.9142837524414\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 81.02816772460938\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 81.13888549804688\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 81.20548248291016\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 81.3648681640625\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 81.27999877929688\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 81.31578826904297\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 81.36363983154297\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 81.5\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 81.46835327148438\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 81.5999984741211\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 81.67901611328125\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 81.78048706054688\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 81.84337615966797\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 81.96428680419922\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 82.04705810546875\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 82.16278839111328\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 82.31034851074219\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 82.48863983154297\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 82.65168762207031\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 82.78888702392578\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 82.75823974609375\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 82.82608795166016\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 82.81720733642578\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 82.95744323730469\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 83.08421325683594\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 83.11458587646484\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 83.0721664428711\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 82.9795913696289\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 82.88888549804688\n",
            "Iteration: 3000. Loss: 1.1216968297958374. Accuracy: 82.83999633789062\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 79.0\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 82.0\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 81.33333587646484\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 80.75\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 80.0\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 79.33333587646484\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.71428680419922\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 79.375\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 80.0\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 79.80000305175781\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 79.63636016845703\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 79.58333587646484\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.53845977783203\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.57142639160156\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.19999694824219\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.4375\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.47058868408203\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.44444274902344\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.47368621826172\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.3499984741211\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.0952377319336\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 77.81818389892578\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.0434799194336\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.125\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.12000274658203\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.03845977783203\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.11111450195312\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.39286041259766\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.55172729492188\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.5999984741211\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.93548583984375\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.71875\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.78787994384766\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.67646789550781\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.77143096923828\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.69444274902344\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.78378295898438\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.60526275634766\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.4871826171875\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.4749984741211\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.48780822753906\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.52381134033203\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.44186401367188\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.2727279663086\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.19999694824219\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.3043441772461\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.44680786132812\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.5625\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.42857360839844\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.41999816894531\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.5882339477539\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 78.80769348144531\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 79.03773498535156\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 79.33333587646484\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 79.69091033935547\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 79.73213958740234\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 79.77192687988281\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 79.93103790283203\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 79.91525268554688\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 79.83333587646484\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 79.86885070800781\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 80.04838562011719\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 80.36508178710938\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 80.53125\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 80.70769500732422\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 80.71212005615234\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 80.7313461303711\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 80.67646789550781\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 80.6956558227539\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 80.81428527832031\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 80.92958068847656\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 81.05555725097656\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 81.1369857788086\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 81.3108139038086\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 81.23999786376953\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 81.27631378173828\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 81.32467651367188\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 81.46154022216797\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 81.43038177490234\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 81.55000305175781\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 81.62963104248047\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 81.73170471191406\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 81.8072280883789\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 81.92857360839844\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 82.0\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 82.11627960205078\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 82.26436614990234\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 82.44318389892578\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 82.60674285888672\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 82.74444580078125\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 82.71428680419922\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 82.78260803222656\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 82.79570007324219\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 82.92552947998047\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 83.04210662841797\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 83.07291412353516\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 83.0412368774414\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 82.95918273925781\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 82.86869049072266\n",
            "Iteration: 3200. Loss: 1.049820899963379. Accuracy: 82.81999969482422\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 81.0\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 82.5\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 82.0\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 81.0\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 80.4000015258789\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 80.0\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.28571319580078\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.875\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 80.66666412353516\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 80.4000015258789\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 80.36363983154297\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 80.33333587646484\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.30769348144531\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.35713958740234\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 78.93333435058594\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.125\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.17646789550781\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.16666412353516\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.15789794921875\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.0\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 78.76190185546875\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 78.45454406738281\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 78.65217590332031\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 78.70833587646484\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 78.68000030517578\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 78.61538696289062\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 78.66666412353516\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 78.96428680419922\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.13793182373047\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.19999694824219\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.51612854003906\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.375\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.42424011230469\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.32353210449219\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.4000015258789\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.30555725097656\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.37837982177734\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.18421173095703\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.05128479003906\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.0\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.0243911743164\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.07142639160156\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 78.9534912109375\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 78.81818389892578\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 78.80000305175781\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 78.89130401611328\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.02127838134766\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.125\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 78.9795913696289\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 78.95999908447266\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.11764526367188\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.34615325927734\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.5660400390625\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 79.85185241699219\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 80.19999694824219\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 80.23213958740234\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 80.28070068359375\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 80.44827270507812\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 80.44068145751953\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 80.3499984741211\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 80.40983581542969\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 80.58064270019531\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 80.88888549804688\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 81.0625\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 81.23076629638672\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 81.2272720336914\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 81.23880767822266\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 81.19117736816406\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 81.20289611816406\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 81.31428527832031\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 81.4366226196289\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 81.55555725097656\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 81.63013458251953\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 81.78378295898438\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 81.72000122070312\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 81.77631378173828\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 81.80519104003906\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 81.93589782714844\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 81.89873504638672\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 82.0250015258789\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 82.09876251220703\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 82.20731353759766\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 82.27710723876953\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 82.38095092773438\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 82.45882415771484\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 82.56977081298828\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 82.712646484375\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 82.88636016845703\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 83.0449447631836\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 83.17778015136719\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 83.14286041259766\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 83.2065200805664\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 83.20429992675781\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 83.34042358398438\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 83.4631576538086\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 83.48958587646484\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 83.47422790527344\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 83.38775634765625\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 83.30303192138672\n",
            "Iteration: 3400. Loss: 1.0357332229614258. Accuracy: 83.25\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 80.0\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 83.0\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 82.66666412353516\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 81.5\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 80.80000305175781\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 80.33333587646484\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.57142639160156\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 80.125\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 80.77777862548828\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 80.5999984741211\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 80.63636016845703\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 80.58333587646484\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.61538696289062\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.57142639160156\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.13333129882812\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.3125\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.35294342041016\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.33333587646484\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.36842346191406\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.25\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.04762268066406\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 78.7727279663086\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.0\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.04166412353516\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.0\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 78.92308044433594\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 78.96295928955078\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.25\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.4137954711914\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.46666717529297\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.7741928100586\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.65625\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.69696807861328\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.61764526367188\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.68571472167969\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.58333587646484\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.64865112304688\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.47368621826172\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.35897064208984\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.30000305175781\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.31707000732422\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.35713958740234\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.25581359863281\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.11363983154297\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.0888900756836\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.17391204833984\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.2978744506836\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.39583587646484\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.2448959350586\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.22000122070312\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.37255096435547\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.59615325927734\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 79.81131744384766\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 80.09259033203125\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 80.43636322021484\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 80.5\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 80.54386138916016\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 80.70689392089844\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 80.71186065673828\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 80.61666870117188\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 80.68852233886719\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 80.8548355102539\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 81.15872955322266\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 81.34375\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 81.5076904296875\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 81.5\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 81.50746154785156\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 81.45587921142578\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 81.4637680053711\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 81.5857162475586\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 81.7042236328125\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 81.81944274902344\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 81.89041137695312\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 82.0540542602539\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 81.98666381835938\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 82.0131607055664\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 82.05194854736328\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 82.17948913574219\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 82.13924407958984\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 82.26249694824219\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 82.33333587646484\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 82.43902587890625\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 82.48192596435547\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 82.58333587646484\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 82.65882110595703\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 82.76744079589844\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 82.90804290771484\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 83.07954406738281\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 83.23595428466797\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 83.36666870117188\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 83.32967376708984\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 83.40217590332031\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 83.41935729980469\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 83.55319213867188\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 83.6736831665039\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 83.69791412353516\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 83.68041229248047\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 83.59183502197266\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 83.49494934082031\n",
            "Iteration: 3600. Loss: 1.0412840843200684. Accuracy: 83.44000244140625\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 81.0\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 82.5\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 82.0\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 81.0\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 80.4000015258789\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 80.0\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.28571319580078\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.875\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 80.66666412353516\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 80.5999984741211\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 80.63636016845703\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 80.41666412353516\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.38461303710938\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.42857360839844\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.0\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.1875\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.23529052734375\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.22222137451172\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.2631607055664\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.1500015258789\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 78.9047622680664\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 78.63636016845703\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 78.86956787109375\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 78.91666412353516\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 78.87999725341797\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 78.80769348144531\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 78.85185241699219\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.14286041259766\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.31034851074219\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.4000015258789\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.70967864990234\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.59375\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.63636016845703\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.55882263183594\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.62857055664062\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.52777862548828\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.62162017822266\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.42105102539062\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.33333587646484\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.30000305175781\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.31707000732422\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.35713958740234\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.25581359863281\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.09091186523438\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.06666564941406\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.15217590332031\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.27659606933594\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.375\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.2448959350586\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.22000122070312\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.37255096435547\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.59615325927734\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 79.81131744384766\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 80.09259033203125\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 80.43636322021484\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 80.48213958740234\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 80.52631378173828\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 80.68965148925781\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 80.67796325683594\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 80.58333587646484\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 80.63934326171875\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 80.80644989013672\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 81.11111450195312\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 81.28125\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 81.44615173339844\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 81.43939208984375\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 81.44776153564453\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 81.39705657958984\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 81.40579986572266\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 81.5142822265625\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 81.63380432128906\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 81.76388549804688\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 81.83561706542969\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 82.0\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 81.93333435058594\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 81.97368621826172\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 82.01298522949219\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 82.14102935791016\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 82.10126495361328\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 82.23750305175781\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 82.30863952636719\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 82.41463470458984\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 82.49397277832031\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 82.5952377319336\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 82.67058563232422\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 82.77906799316406\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 82.91954040527344\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 83.09091186523438\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 83.26966094970703\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 83.4000015258789\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 83.37362670898438\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 83.4456558227539\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 83.46236419677734\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 83.59574127197266\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 83.71578979492188\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 83.73958587646484\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 83.7319564819336\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 83.64286041259766\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 83.54545593261719\n",
            "Iteration: 3800. Loss: 0.9786159992218018. Accuracy: 83.48999786376953\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.0\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 83.5\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 82.66666412353516\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.75\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.0\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 80.5\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.71428680419922\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 80.25\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.0\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.0\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.09091186523438\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 80.91666412353516\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.92308044433594\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 80.0\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.53333282470703\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.75\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.82353210449219\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.77777862548828\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.78947448730469\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.6500015258789\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.38095092773438\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.13636016845703\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.34782409667969\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.41666412353516\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.36000061035156\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.26923370361328\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.29629516601562\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.57142639160156\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.75862121582031\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.86666870117188\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 80.12903594970703\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 80.03125\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 80.09091186523438\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 80.02941131591797\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 80.11428833007812\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 80.0\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 80.0810775756836\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.86842346191406\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.76923370361328\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.7249984741211\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.70731353759766\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.73809814453125\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.65116119384766\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.5227279663086\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.53333282470703\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.63043212890625\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.74468231201172\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.83333587646484\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.71428680419922\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.68000030517578\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 79.82353210449219\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 80.03845977783203\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 80.24528503417969\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 80.51851654052734\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 80.85454559326172\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 80.91071319580078\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 80.92982482910156\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.10344696044922\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.08474731445312\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 80.98332977294922\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.04917907714844\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.20967864990234\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.5079345703125\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.671875\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.83077239990234\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.81818389892578\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.82089233398438\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.76470947265625\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.76811218261719\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.87142944335938\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 81.98591613769531\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 82.11111450195312\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 82.19178009033203\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 82.35134887695312\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 82.2933349609375\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 82.34210205078125\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 82.40259552001953\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 82.52564239501953\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 82.48101043701172\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 82.61250305175781\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 82.67901611328125\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 82.79268646240234\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 82.85542297363281\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 82.95237731933594\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 83.02352905273438\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 83.1279067993164\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 83.26436614990234\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 83.43181610107422\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 83.59550476074219\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 83.72222137451172\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 83.69230651855469\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 83.76087188720703\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 83.7741928100586\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 83.90425872802734\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 84.02104949951172\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 84.04166412353516\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 84.0412368774414\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 83.94898223876953\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 83.85858917236328\n",
            "Iteration: 4000. Loss: 0.9717420935630798. Accuracy: 83.80000305175781\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.0\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 84.0\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 83.0\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.25\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 81.4000015258789\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.83333587646484\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.0\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.5\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 81.11111450195312\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 81.0999984741211\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 81.18181610107422\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 81.0\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.0\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.07142639160156\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 79.73332977294922\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.0\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.11764526367188\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.05555725097656\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.10526275634766\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 79.94999694824219\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 79.71428680419922\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 79.45454406738281\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 79.65217590332031\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 79.75\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 79.72000122070312\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 79.61538696289062\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 79.62963104248047\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 79.92857360839844\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.10344696044922\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.16666412353516\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.51612854003906\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.4375\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.51515197753906\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.44117736816406\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.5142822265625\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.38888549804688\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.45945739746094\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.2631607055664\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.15384674072266\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.1500015258789\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.1219482421875\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.14286041259766\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.0465087890625\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 79.90908813476562\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 79.93333435058594\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.02173614501953\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.1276626586914\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.20833587646484\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.08163452148438\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.04000091552734\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.17646789550781\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.38461303710938\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.58490753173828\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 80.85185241699219\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 81.18181610107422\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 81.23213958740234\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 81.29824829101562\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 81.46551513671875\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 81.45762634277344\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 81.3499984741211\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 81.40983581542969\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 81.56451416015625\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 81.85713958740234\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.03125\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.18461608886719\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.16666412353516\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.16417694091797\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.10294342041016\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.10144805908203\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.21428680419922\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.32394409179688\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.44444274902344\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.50685119628906\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.66216278076172\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.5999984741211\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.64473724365234\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.70130157470703\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.82051086425781\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.7848129272461\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.9124984741211\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 82.97531127929688\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 83.08536529541016\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 83.13253021240234\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 83.22618865966797\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 83.29412078857422\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 83.39534759521484\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 83.52873229980469\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 83.69318389892578\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 83.86516571044922\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 83.9888916015625\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 83.95604705810547\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 84.02173614501953\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 84.03225708007812\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 84.15957641601562\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 84.273681640625\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 84.30208587646484\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 84.29896545410156\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 84.2040786743164\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 84.10101318359375\n",
            "Iteration: 4200. Loss: 0.9771894812583923. Accuracy: 84.04000091552734\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.0\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 84.0\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 83.0\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.25\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 81.4000015258789\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.83333587646484\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.0\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.5\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 81.11111450195312\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 81.0999984741211\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 81.18181610107422\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 81.0\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.0\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.07142639160156\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 79.73332977294922\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.0\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.11764526367188\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.05555725097656\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.0526351928711\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 79.9000015258789\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 79.61904907226562\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 79.36363983154297\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 79.56521606445312\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 79.70833587646484\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 79.63999938964844\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 79.53845977783203\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 79.55555725097656\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 79.82142639160156\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.0\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.06666564941406\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.38710021972656\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.28125\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.36363983154297\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.29412078857422\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.42857360839844\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.30555725097656\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.40540313720703\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.18421173095703\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.07691955566406\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.07499694824219\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.07317352294922\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.0952377319336\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.0\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 79.88636016845703\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 79.9111099243164\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.0\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.1276626586914\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.20833587646484\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.08163452148438\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.05999755859375\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.21568298339844\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.42308044433594\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.62264251708984\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 80.88888549804688\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 81.21818542480469\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 81.26786041259766\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 81.29824829101562\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 81.46551513671875\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 81.45762634277344\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 81.3499984741211\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 81.40983581542969\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 81.56451416015625\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 81.85713958740234\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.03125\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.18461608886719\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.16666412353516\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.16417694091797\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.10294342041016\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.10144805908203\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.19999694824219\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.30986022949219\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.43055725097656\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.50685119628906\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.67567443847656\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.63999938964844\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.67105102539062\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.7272720336914\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.84615325927734\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.81012725830078\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 82.9375\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 83.0\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 83.1219482421875\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 83.18072509765625\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 83.27381134033203\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 83.34117889404297\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 83.44186401367188\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 83.5862045288086\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 83.75\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 83.92134857177734\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 84.04444122314453\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 84.010986328125\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 84.07608795166016\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 84.10752868652344\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 84.23403930664062\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 84.34736633300781\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 84.375\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 84.37113189697266\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 84.2755126953125\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 84.17171478271484\n",
            "Iteration: 4400. Loss: 0.9217494130134583. Accuracy: 84.11000061035156\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 82.0\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 84.5\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 84.0\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 83.0\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 82.5999984741211\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 81.83333587646484\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 81.0\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 81.375\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 82.11111450195312\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 82.0\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 82.0\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 81.83333587646484\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.76923370361328\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.78571319580078\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.46666717529297\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.6875\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.76470947265625\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.61111450195312\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.68421173095703\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.5\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.19047546386719\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 79.90908813476562\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.08695983886719\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.20833587646484\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.12000274658203\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.0\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.0\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.28571319580078\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.55172729492188\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.5999984741211\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.87096405029297\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.75\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.81818389892578\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.76470947265625\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.85713958740234\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.72222137451172\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.8108139038086\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.57894897460938\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.5128173828125\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.5250015258789\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.53658294677734\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.54762268066406\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.46511840820312\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.34091186523438\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.35555267333984\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.41304016113281\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.53191375732422\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.64583587646484\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.53060913085938\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.54000091552734\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.68627166748047\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 80.88461303710938\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 81.07546997070312\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 81.33333587646484\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 81.65454864501953\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 81.69642639160156\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 81.7368392944336\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 81.89655303955078\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 81.86441040039062\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 81.76667022705078\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 81.81967163085938\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 81.95161437988281\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 82.23809814453125\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 82.40625\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 82.55384826660156\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 82.53030395507812\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 82.52238464355469\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 82.45587921142578\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 82.4637680053711\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 82.55714416503906\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 82.66197204589844\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 82.77777862548828\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 82.84931182861328\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 83.0\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 82.97333526611328\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 83.02631378173828\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 83.09091186523438\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 83.20513153076172\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 83.16455841064453\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 83.2874984741211\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 83.3456802368164\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 83.46341705322266\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 83.51807403564453\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 83.60713958740234\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 83.67058563232422\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 83.76744079589844\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 83.90804290771484\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 84.06818389892578\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 84.23595428466797\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 84.35555267333984\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 84.31867980957031\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 84.38043212890625\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 84.40859985351562\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 84.54255676269531\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 84.66315460205078\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 84.70833587646484\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 84.70103454589844\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 84.60204315185547\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 84.49494934082031\n",
            "Iteration: 4600. Loss: 0.920941174030304. Accuracy: 84.43000030517578\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.0\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 84.5\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 84.33333587646484\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 83.25\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.80000305175781\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.0\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 81.28571319580078\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 81.75\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.33333587646484\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.19999694824219\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.18181610107422\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.0\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.92308044433594\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.92857360839844\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.5999984741211\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.8125\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.82353210449219\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.66666412353516\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.68421173095703\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.5\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.23809814453125\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 79.95454406738281\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.13043212890625\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.25\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.19999694824219\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.07691955566406\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.0740737915039\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.32142639160156\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.62068939208984\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.66666412353516\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 81.0\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.875\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.93939208984375\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.88235473632812\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.97142791748047\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.83333587646484\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.9459457397461\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.7368392944336\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.66666412353516\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.69999694824219\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.70731353759766\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.69047546386719\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.60465240478516\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.4772720336914\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.4888916015625\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.5434799194336\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.65957641601562\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.77083587646484\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.67346954345703\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.68000030517578\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 80.82353210449219\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 81.01923370361328\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 81.2264175415039\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 81.48148345947266\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 81.80000305175781\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 81.83928680419922\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 81.87718963623047\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.03448486328125\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.01695251464844\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 81.91666412353516\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 81.96721649169922\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.09677124023438\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.38095092773438\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.5625\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.70769500732422\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.69696807861328\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.68656921386719\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.61764526367188\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.63768005371094\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.74285888671875\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.8450698852539\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 82.95833587646484\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 83.02739715576172\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 83.20270538330078\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 83.17333221435547\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 83.22368621826172\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 83.28571319580078\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 83.3974380493164\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 83.35443115234375\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 83.4749984741211\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 83.5308609008789\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 83.6463394165039\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 83.67469787597656\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 83.76190185546875\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 83.82353210449219\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 83.9186019897461\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 84.0574722290039\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 84.21591186523438\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 84.38201904296875\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 84.5\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 84.46154022216797\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 84.53260803222656\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 84.54838562011719\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 84.68085479736328\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 84.80000305175781\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 84.84375\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 84.83505249023438\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 84.73469543457031\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 84.62625885009766\n",
            "Iteration: 4800. Loss: 0.9247666001319885. Accuracy: 84.55999755859375\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.0\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 84.5\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 84.33333587646484\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 83.25\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.80000305175781\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.0\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 81.14286041259766\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 81.75\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.44444274902344\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.30000305175781\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.2727279663086\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.08333587646484\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 81.0\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 81.0\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.66666412353516\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.875\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.94117736816406\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.77777862548828\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.89473724365234\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.69999694824219\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.38095092773438\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.09091186523438\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.26087188720703\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.375\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.27999877929688\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.15384674072266\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.14814758300781\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.39286041259766\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.62068939208984\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.69999694824219\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.96774291992188\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.84375\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.90908813476562\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.88235473632812\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 81.0\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.86111450195312\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.9459457397461\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.71052551269531\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.64102935791016\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.6500015258789\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.65853881835938\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.64286041259766\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.55813598632812\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.45454406738281\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.4888916015625\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.58695983886719\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.72340393066406\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.83333587646484\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.71428680419922\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.72000122070312\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 80.86274719238281\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 81.07691955566406\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 81.28302001953125\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 81.53704071044922\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 81.85454559326172\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 81.89286041259766\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 81.92982482910156\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.0862045288086\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.06779479980469\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 81.96666717529297\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.01639556884766\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.1451644897461\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.42857360839844\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.59375\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.73846435546875\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.7272720336914\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.7313461303711\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.6617660522461\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.66666412353516\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.75714111328125\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.87323760986328\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 82.98611450195312\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 83.05479431152344\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 83.21621704101562\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 83.1866683959961\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 83.25\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 83.31169128417969\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 83.42308044433594\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 83.37974548339844\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 83.51249694824219\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 83.56790161132812\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 83.68292999267578\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 83.72289276123047\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 83.80952453613281\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 83.87059020996094\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 83.96511840820312\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 84.10344696044922\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 84.26136016845703\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 84.42696380615234\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 84.54444122314453\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 84.5054931640625\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 84.56521606445312\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 84.6021499633789\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 84.74468231201172\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 84.85263061523438\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 84.89583587646484\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 84.8865966796875\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 84.78571319580078\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 84.6868667602539\n",
            "Iteration: 5000. Loss: 0.8751102685928345. Accuracy: 84.6500015258789\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.0\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 84.5\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 84.33333587646484\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 83.25\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.80000305175781\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.83333587646484\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.14286041259766\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.75\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.66666412353516\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.5999984741211\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.54545593261719\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.25\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.15384674072266\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.21428680419922\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.86666870117188\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.1875\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.29412078857422\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.11111450195312\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.21052551269531\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.0\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.76190185546875\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.40908813476562\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.56521606445312\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.66666412353516\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.5999984741211\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.46154022216797\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.44444274902344\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.71428680419922\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.03448486328125\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.06666564941406\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.32257843017578\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.1875\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.24242401123047\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.17646789550781\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.28571319580078\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.13888549804688\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.27027130126953\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.02631378173828\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.94871520996094\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.9749984741211\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.9756088256836\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.97618865966797\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.88372039794922\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.7727279663086\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.82221984863281\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.89130401611328\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.0\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.10416412353516\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.9795913696289\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 80.9800033569336\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.11764526367188\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.30769348144531\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.50943756103516\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 81.77777862548828\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.09091186523438\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.125\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.15789794921875\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.31034851074219\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.30508422851562\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.19999694824219\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.24590301513672\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.37096405029297\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.65079498291016\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.828125\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.96923065185547\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.95454406738281\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.97014617919922\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.89705657958984\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 82.94203186035156\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 83.02857208251953\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 83.12676239013672\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 83.23611450195312\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 83.3013687133789\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 83.47297668457031\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 83.44000244140625\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 83.5131607055664\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 83.58441925048828\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 83.69230651855469\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 83.64556884765625\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 83.7750015258789\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 83.82716369628906\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 83.93902587890625\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 83.98795318603516\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 84.07142639160156\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 84.12940979003906\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 84.22093200683594\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 84.3563232421875\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 84.51136016845703\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 84.67415618896484\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 84.78888702392578\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 84.74725341796875\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 84.81521606445312\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 84.83870697021484\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 84.96808624267578\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 85.08421325683594\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 85.125\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 85.1134033203125\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 85.0204086303711\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 84.919189453125\n",
            "Iteration: 5200. Loss: 0.8796393871307373. Accuracy: 84.87999725341797\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 82.0\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 84.5\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 84.33333587646484\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 83.25\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 82.80000305175781\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.83333587646484\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.14286041259766\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.875\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 82.66666412353516\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 82.5999984741211\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 82.63636016845703\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 82.33333587646484\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.23076629638672\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.35713958740234\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.06666564941406\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.3125\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.29412078857422\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.11111450195312\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.21052551269531\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.05000305175781\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 80.85713958740234\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 80.5\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 80.65217590332031\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 80.75\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 80.76000213623047\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 80.65384674072266\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 80.62963104248047\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 80.85713958740234\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.17241668701172\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.23332977294922\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.51612854003906\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.375\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.42424011230469\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.4117660522461\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.5142822265625\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.36111450195312\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.48648834228516\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.2631607055664\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.15384674072266\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.17500305175781\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.17073059082031\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.14286041259766\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.0465087890625\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 80.93181610107422\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 80.97777557373047\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.0434799194336\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.14893341064453\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.25\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.14286041259766\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.13999938964844\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.2745132446289\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.44230651855469\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.64151000976562\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 81.90740966796875\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 82.21818542480469\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 82.28571319580078\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 82.33333587646484\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 82.48275756835938\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 82.47457885742188\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 82.36666870117188\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 82.40983581542969\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 82.53225708007812\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 82.80952453613281\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 82.984375\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 83.12307739257812\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 83.10606384277344\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 83.11940002441406\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 83.04412078857422\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 83.07246398925781\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 83.17142486572266\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 83.28169250488281\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 83.38888549804688\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 83.46575164794922\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 83.6351318359375\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 83.5999984741211\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 83.64473724365234\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 83.71428680419922\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 83.82051086425781\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 83.77214813232422\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 83.88749694824219\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 83.93827056884766\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 84.04878234863281\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 84.08433532714844\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 84.16666412353516\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 84.22352600097656\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 84.3255844116211\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 84.45977020263672\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 84.61363983154297\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 84.77528381347656\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 84.88888549804688\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 84.84615325927734\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 84.91304016113281\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 84.93548583984375\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 85.06382751464844\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 85.17894744873047\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 85.20833587646484\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 85.19587707519531\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 85.10204315185547\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 85.0\n",
            "Iteration: 5400. Loss: 0.8809713125228882. Accuracy: 84.94999694824219\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 82.0\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 84.5\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 84.66666412353516\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.5\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.0\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 82.0\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.28571319580078\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.875\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 82.66666412353516\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 82.5999984741211\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 82.54545593261719\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 82.25\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.15384674072266\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.35713958740234\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.06666564941406\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.375\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.4117660522461\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.22222137451172\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.36842346191406\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.0999984741211\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 80.9047622680664\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 80.54545593261719\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 80.6956558227539\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 80.79166412353516\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 80.72000122070312\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 80.61538696289062\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 80.59259033203125\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 80.82142639160156\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.13793182373047\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.19999694824219\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.48387145996094\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.34375\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.39393615722656\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.35294342041016\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.45714569091797\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.30555725097656\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.43243408203125\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.18421173095703\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.07691955566406\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.0999984741211\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.09756469726562\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.07142639160156\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.0\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 80.93181610107422\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 80.97777557373047\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.0434799194336\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.17021179199219\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.27083587646484\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.16326904296875\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.16000366210938\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.29412078857422\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.48076629638672\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.67924499511719\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 81.94444274902344\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 82.25454711914062\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 82.28571319580078\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 82.33333587646484\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 82.48275756835938\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 82.47457885742188\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 82.36666870117188\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 82.40983581542969\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 82.53225708007812\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 82.80952453613281\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 82.96875\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.12307739257812\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.10606384277344\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.11940002441406\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.04412078857422\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.07246398925781\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.15714263916016\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.28169250488281\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.38888549804688\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.46575164794922\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.62162017822266\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.586669921875\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.65789794921875\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.7272720336914\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.83333587646484\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.7848129272461\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.9124984741211\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 83.96295928955078\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 84.07317352294922\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 84.1204833984375\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 84.20237731933594\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 84.28235626220703\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 84.38372039794922\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 84.51724243164062\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 84.68181610107422\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 84.84269714355469\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 84.95555877685547\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 84.9120864868164\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 84.97826385498047\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 85.0215072631836\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 85.15957641601562\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 85.2631607055664\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 85.3125\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 85.29896545410156\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 85.2040786743164\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 85.11111450195312\n",
            "Iteration: 5600. Loss: 0.8360236287117004. Accuracy: 85.06999969482422\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 82.0\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 84.5\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 84.66666412353516\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.5\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.0\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 82.16666412353516\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.57142639160156\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 82.25\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.11111450195312\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.0\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.0\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 82.66666412353516\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.53845977783203\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.71428680419922\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.5999984741211\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.875\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.88235473632812\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.66666412353516\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.84210205078125\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.5999984741211\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.38095092773438\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.0\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.13043212890625\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.20833587646484\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.23999786376953\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.11538696289062\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.0740737915039\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.28571319580078\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.5862045288086\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.5999984741211\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.87096405029297\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.75\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.78787994384766\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.76470947265625\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.85713958740234\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.69444274902344\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.8108139038086\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.5526351928711\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.43589782714844\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.4749984741211\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.48780822753906\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.47618865966797\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.39534759521484\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.31818389892578\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.35555267333984\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.41304016113281\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.53191375732422\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.625\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.51020050048828\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.5\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.62744903564453\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.78845977783203\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 81.98113250732422\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 82.24073791503906\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 82.54545593261719\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 82.60713958740234\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 82.64912414550781\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 82.79310607910156\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 82.7796630859375\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 82.66666412353516\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 82.70491790771484\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 82.82257843017578\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.0952377319336\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.265625\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.4000015258789\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.39393615722656\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.40298461914062\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.32353210449219\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.36231994628906\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.44285583496094\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.5633773803711\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.66666412353516\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.7397232055664\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.90540313720703\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.86666870117188\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 83.93421173095703\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 84.0\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 84.1025619506836\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 84.0506362915039\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 84.1624984741211\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 84.20987701416016\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 84.31707000732422\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 84.37349700927734\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 84.45237731933594\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 84.52941131591797\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 84.6279067993164\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 84.78160858154297\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 84.93181610107422\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 85.08988952636719\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 85.19999694824219\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 85.15384674072266\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 85.21739196777344\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 85.25806427001953\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 85.39361572265625\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 85.50526428222656\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 85.54166412353516\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 85.52577209472656\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 85.42857360839844\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 85.33333587646484\n",
            "Iteration: 5800. Loss: 0.8453806042671204. Accuracy: 85.29000091552734\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 82.0\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 84.5\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 84.66666412353516\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 83.5\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 83.0\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 82.16666412353516\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.57142639160156\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 82.25\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 83.0\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 82.9000015258789\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 82.90908813476562\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 82.58333587646484\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.53845977783203\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.71428680419922\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.5999984741211\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.875\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.94117736816406\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.77777862548828\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.9473648071289\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.75\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.52381134033203\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.13636016845703\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.26087188720703\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.29166412353516\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.31999969482422\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.19230651855469\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.14814758300781\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.35713958740234\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.6551742553711\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.69999694824219\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.96774291992188\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.84375\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.90908813476562\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.88235473632812\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.97142791748047\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.80555725097656\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.9189224243164\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.71052551269531\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.5897445678711\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.625\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.65853881835938\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.64286041259766\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.55813598632812\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.4772720336914\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.5111083984375\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.56521606445312\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.65957641601562\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.75\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.65306091308594\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.62000274658203\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.7450942993164\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 81.92308044433594\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 82.11320495605469\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 82.37036895751953\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 82.6727294921875\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 82.73213958740234\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 82.78947448730469\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 82.93103790283203\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 82.91525268554688\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 82.80000305175781\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 82.83606719970703\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 82.95161437988281\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 83.22222137451172\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 83.390625\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 83.53845977783203\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 83.51515197753906\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 83.52238464355469\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 83.44117736816406\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 83.4637680053711\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 83.55714416503906\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 83.67605590820312\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 83.77777862548828\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 83.84931182861328\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 84.01351165771484\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 83.97333526611328\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 84.03947448730469\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 84.10389709472656\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 84.20513153076172\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 84.15190124511719\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 84.26249694824219\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 84.30863952636719\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 84.41463470458984\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 84.45783233642578\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 84.53571319580078\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 84.61176300048828\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 84.70930480957031\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 84.86206817626953\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 85.01136016845703\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 85.16854095458984\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 85.27777862548828\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 85.23076629638672\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 85.2934799194336\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 85.33333587646484\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 85.46808624267578\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 85.56842041015625\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 85.61458587646484\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 85.59793853759766\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 85.5\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 85.40403747558594\n",
            "Iteration: 6000. Loss: 0.8437364101409912. Accuracy: 85.36000061035156\n",
            "Final Accuracy: tensor(85.3600)\n"
          ]
        }
      ]
    }
  ]
}